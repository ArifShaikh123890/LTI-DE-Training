******************************************************************************************
			Socket Streaming:
******************************************************************************************
nc -lk 8476
pyspark --master local --conf "spark.sql.shuffle.partitions=2"
from pyspark.sql.functions import split, explode

host="localhost"
port=8476

lines = spark.readStream.format("socket").option("host",host).option("port",port).load()

words = lines.select(explode(split("value", " ")).alias("word"))

wordsCount = words.groupBy("word").count()

query = wordsCount.writeStream.outputMode("complete").format("console").start()
******************************************************************************************
			File streaming:
******************************************************************************************
from pyspark.sql import SparkSession
from pyspark.sql.functions import *
from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType

spark = SparkSession.builder.appName('File Streaming').config('spark.sql.shuffle.partitions','2').master('local[*]').getOrCreate()

schema = StructType([StructField('emp_id', IntegerType(), True),
		StructField('emp_name', StringType(), True),
		StructField('job_name', StringType(), True),
		StructField('magr_id', IntegerType(), True),
		StructField('salary', IntegerType(), True),
		StructField('dept_name', StringType(), True)])

custDf = spark.readStream.format('csv').schema(schema).option('header',True).load('hdfs://cdhserver:8020/user/labuser/HFS/Input/streaming/')

empCnt = custDf.groupBy('job_name').count()

empCnt.writeStream.outputMode("complete").format("console").start().awaitTermination()
******************************************************************************************
