******************************************************************************************
			Socket Streaming:
******************************************************************************************
nc -lk 8476
pyspark --master local --conf "spark.sql.shuffle.partitions=2"
from pyspark.sql.functions import split, explode

host="localhost"
port=8476

lines = spark.readStream.format("socket").option("host",host).option("port",port).load()

words = lines.select(explode(split("value", " ")).alias("word"))

wordsCount = words.groupBy("word").count()

query = wordsCount.writeStream.outputMode("complete").format("console").start()
******************************************************************************************
			File streaming:
******************************************************************************************
from pyspark.sql import SparkSession
from pyspark.sql.functions import
from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType

spark = SparkSession.builder.appName('File Streaming').config('spark.sql.shuffle.partitions'='2').master(local['*']).getOrCreate()

schema = StructType([StructField(emp_id, IntegerType(), True),
		StructField(emp_id, IntegerType(), True),
		StructField(emp_id, IntegerType(), True),
		StructField(emp_id, IntegerType(), True),
		StructField(emp_id, IntegerType(), True),
		StructField(emp_id, IntegerType(), True)])

custDf = spark.readStream.format('csv').schema(schema).option('header',True).load()

empCnt = empDf.groupBy('job_name').count()

empCnt.writeStream.outputMode("complete").format("console").start().awaitTermination()
******************************************************************************************
