from pyspark.sql import SparkSession
from pyspark.sql.functions import col, split, explode, count, substring, length, expr, regexp_replace
from pyspark.sql.types import StructType, StructField, IntegerType, StringType

def create_spark_session(an: 'Streaming', m: 'local[*]'):
    spark = SparkSession.builder\
             .appName(an).master(m).getOrCreate()
    return spark

mySchema = StructType([
    StructField('movieId', IntegerType()),
    StructField('title', StringType()),
    StructField('genres', StringType()),
])
def read_movies(file_path):
    moviesDf = spark.readStream.format('csv')\
                .option('header','true')\
                .schema(mySchema)\
                .load(file_path)
    return moviesDf
file_path = 'hdfs://cdhserver:8020/user/labuser/HFS/Input/Streaming/'

if __name__ == '__main__':
    spark = create_spark_session('File Streaming', 'local[*]')
    # print(spark)

    movDf = read_movies(file_path)
    # movDf.show(5, truncate=False)

    # withColumn("New_Year", expr("substring(title, -5, 4)"))
    resDf = movDf.withColumn("New_Title", expr("substring(title, 1, length(title)-6)")) \
        .withColumn("New_Year", expr("substring(title, -6, 6)")) \
        .withColumn("New_Year", regexp_replace(col("New_Year"), "[\(,\)]", "")) \
        .withColumn("New_Genres", explode(split(col("genres"), "\|")))
    # resDf.show(5, truncate=False)

    res = resDf.writeStream.format('console').outputMode('append').start()
    res.awaitTermination()
